# A Query Engine
Goal: Run TPC-H queries using a query engine built from scratch.
Non-goals:
- parse SQL: I will provide ready-to-use ASTs in relational algebra.
- optimize queries: queries will be executed as-is.
- any SQL functionalities not required for the TPC-H benchmarks.

## TPC-H setup
DuckDB has a setup for running TPC-H queries which we can reuse.
This includes the SQL files containing the queries, and a tool for generating the TPC-H dataset as a parquet file.
My engine will need to **support reading parquet files** so that we can use the dataset generated by DuckDB.

To generate the dataset I [built the DuckDB benchmark setup](https://github.com/duckdb/duckdb/tree/main/benchmark) and ran:

```shell
./build/release/benchmark/benchmark_runner benchmark/tpch/sf1-parquet/q01.benchmark
```

This produces the TPC-H dataset at scaling factor 1 under `duckdb_benchmark_data/tpch_sf1_parquet`.

The SQL queries for TPC-H are also available from the DuckDB repo.
They are stored under `extension/tpch/dbgen/queries`.
The expected output per query is stored as a CSV under `extension/tpch/dbgen/answers/sf1`.

## Towards the first query
The first TPC-H query is:

```sql
SELECT
    l_returnflag,
    l_linestatus,
    sum(l_quantity) AS sum_qty,
    sum(l_extendedprice) AS sum_base_price,
    sum(l_extendedprice * (1 - l_discount)) AS sum_disc_price,
    sum(l_extendedprice * (1 - l_discount) * (1 + l_tax)) AS sum_charge,
    avg(l_quantity) AS avg_qty,
    avg(l_extendedprice) AS avg_price,
    avg(l_discount) AS avg_disc,
    count(*) AS count_order
FROM
    lineitem
WHERE
    l_shipdate <= CAST('1998-09-02' AS date)
GROUP BY
    l_returnflag,
    l_linestatus
ORDER BY
    l_returnflag,
    l_linestatus;
```

This query is relatively simple and does not require many joins.
My engine needs to support the following operators:
- Parquet scanner: for reading base table data.
- Selection: for filtering (`WHERE`) based on shipping date
- Aggregation: for `GROUP BY`. With support for `count(*)`, `sum` and `avg` aggregation functions.
- Sorting: for `ORDER BY`
- Projection: for `SELECT`. Must have support for complex expresions with arithmetic.

Data types used:
- `INTEGER`: signed 4-byte integer (32-bit).
- `DECIMAL(15,2)`: fixed-precisions number with width 15, scale 2.
- `VARCHAR`: variable-length string. Not sure if UTF-8.
- `DATE`: calendar date (year, month, day).
All non-null.

## Reading parquet
I can use the official Apache Arrow library, which is the official library to read parquet files.
For best performance, I should use the [datasets API](https://arrow.apache.org/docs/cpp/dataset.html#cpp-dataset).

TODO: setup a demo for the C++ API to read the DuckDB parquet files.

## Architecture
The engine is optimized for analytical queries.
Properties:
- Columnar storage and vectorized execution: communication between operators is done with chunks of data (about 10K tuples).
- Partitioning: TODO figure this out.
- Bottom-up evaluation: Execution begins at the leaf nodes of the query plan, and pushes chunks up to their parent operators.
- Morsel-driven parallelism. 
  Rather than schedule work for a single operator, we assign threads to process all operators for a given block up to the next pipeline breaker.

Stretch goal: compilation via MLIR.

## Dependencies
I need LLVM and Arrow.
LLVM has bazel support, but this is not available for Arrow.
Packages for arrow are also not available in the ubuntu repos.
Due to this, I choose to go with a CMake-based setup for now.

### Arrow
- Downloaded https://dlcdn.apache.org/arrow/arrow-13.0.0/apache-arrow-13.0.0.tar.gz.
- Configured as: `cmake .. --preset ninja-release -DCMAKE_EXPORT_COMPILE_COMMANDS=1 -DCMAKE_INSTALL_PREFIX=install/ -DARROW_BUILD_STATIC`
- Build & Install: `cmake --build . && cmake --install .`

I am enabling the static library build because I saw errors trying to find libarrow if I link to libparquet.
Most likely libparquet wants to link to the libarrow in the same directory, but because we have not installed it to a system directory, it cannot be found.

### Final incantation
```
cmake .. \
    -DCMAKE_EXPORT_COMPILE_COMMANDS=1 -G Ninja \
    -DParquet_DIR=/home/daan/workspace/apache-arrow-13.0.0/cpp/build/install/lib/cmake/Parquet \
    -DArrow_DIR=/home/daan/workspace/apache-arrow-13.0.0/cpp/build/install/lib/cmake/Arrow
```