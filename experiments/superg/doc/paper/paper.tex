\documentclass[conference]{IEEEtran}

\usepackage{cite}
\usepackage[pdftex]{graphicx}
% declare the path(s) where your graphic files are
\graphicspath{{images/}}

% Packages that are sometimes useful
%\usepackage{amsmath,amssymb,amsfonts}
%\usepackage{algorithmic}
%\usepackage{float}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Reviving the Lost Art of Combinator Graph Reduction},
    pdfpagemode=FullScreen,
    }

\urlstyle{same}

\usepackage{amsmath}
\DeclareMathOperator{\strict}{strict}
\DeclareMathOperator{\lazy}{lazy}
\DeclareMathOperator{\lazyeta}{lazy_\eta}
\DeclareMathOperator{\linear}{linear}

\begin{document}

\title{Reviving the Lost Art of Combinator Graph Reduction}

\author{\IEEEauthorblockN{Daan de Graaf}
    \IEEEauthorblockA{\textit{Master's student Computer Engineering} \\
        \textit{TU Delft / Eindhoven University of Technology}\\
        Eindhoven, Netherlands \\
        d.j.a.degraaf@student.tudelft.nl / d.j.a.d.graaf@student.tue.nl}
}

\maketitle

\begin{abstract}
    % Rules of thumb
    % - 1 sentence background
    % - 1 sentence motive/problem
    % - 1 sentence objective
    % - 1 sentence approach/method
    % - 2 sentences support
    % - 1 sentence conclusion
    % - 1 sentence implication
    % - 1 sentence limitation
    This is the abstract.
\end{abstract}

\begin{IEEEkeywords}
    combinatory logic, graph reduction, lazy functional language, lazy evaluation
\end{IEEEkeywords}

\section{Introduction}
% Why did I research this? Give the motive, usually a knowledge gap or problem
Lazy evaluation of programs is a powerful idea.
It allows a program to operate on infinitely large data structures, and if part of the computation turns out to be unnecessary, it is more efficient than a strict evaluation.
In practice, delaying computation often introduces overhead, making languages based on lazy evaluation slower than their strict counterparts.
To compete with a strict implementation, a lazy runtime must maximize laziness while minimizing overhead.
It is a difficult balance, and over the years many different evaluator designs, or \textit{abstract machines}, have been proposed~\cite{turner_new_1979,kieburtz_g-machine_1985,fairbairn_tim_1987,burn_spineless_1988,koopman_fresh_1989,jones_implementing_nodate}.

One of the early approaches to implementing lazy functional languages is combinator graph reduction~\cite{turner_new_1979}.
It was the basis for David Turner's Miranda language~\cite{turner_miranda_1985}, the popular choice for pure functional languages and one of the few to be commercially supported at the time.
Eventually, the interest in Miranda and combinator graph reduction with it waned.
Part of the reason may be that Miranda was until very recently a closed-source, licensed software (its source code was released only in 2020~\cite{noauthor_open_2021}), leading to the creation of the open-source Haskell language~\cite{hudak_history_2007}.
But combinator reduction also deserves part of the blame.
% Firstly, owing to the simplicity of individual combinators, expressions are reduced in many small steps, so the per-step overhead greatly impacts runtime performance.
% Every reduction step modifies the stack and usually also the graph, resulting in high memory traffic.
One of the major issues is that the translation to combinators may result in much larger programs.
For a lambda calculus expression of size $N$, the traditional bracket abstraction algorithm produces an output of $O(N^2)$ in the worst case, where other approaches such as supercombinators are linear\cite{spj_impl}.
Larger programs run slower, and along with other disadvantages, this led to combinator graph reduction being all but abandoned.

% What did I research?
% - Research problem/question
%   * Definitions
%   * Choices
%   * Presuppositions
% - Why specifically this research question?
%   * Theoretical or societal relevance
Recently, however, a new algorithm for the translation of lambda calculus expressions into combinatory logic has been proposed that is linear in the size of the input\cite{kiselyov_lambda_2018}.
Kiselyov's translation algorithm is based on semantics rather than syntax and this deeper understanding of the program has been shown to produce more compact translations.
While a clear improvement over previous translation strategies, it remains to be seen how big the impact is on real-world performance.
Is it enough to bridge the performance gap with newer reduction engines based on different paradigms?
This leads us to our first research question:

\textbf{RQ1:} Does Kiselyov's semantic translation make combinator graph reduction competitive with contemporary lazy functional evaluators?

% How did I research this?
% - Methods
% - Sub-questions
We use GHC as the reference for a contemporary evaluator, and then measure the execution time of a set of benchmark programs.
We also need a fast reduction engine that can run programs compiled to combinator expressions.
Alas, there is no performant reduction engine tailored to executing such programs.
The now open-sourced Miranda is a good starting point, but it is showing its age.
The 2020 port compiles cleanly on a recent GCC, but enabling optimizations is known to break the garbage collector.
Miranda's architecture is based on cells with a tag, head and tail as described in\cite{turner_new_1979}, but later work has shown that a tagless representation with direct pointers to code leads to better performance\cite{koopman_fresh_1989}.
In absence of an up-to-date reference on building a practical combinator reduction engine, we formulate the second research question:

\textbf{RQ2:} How is combinator graph reduction implemented efficiently on conventional hardware?

We evaluate the state of the art in combinator graph reduction and build a fast implementation for a language that is simple but powerful enough to express our benchmark programs.
Using this engine, we can then answer \textbf{RQ1}.

% How did I organize the report?
% - Structure Overview
Concretely, our contributions are the following:
\begin{itemize}
    \item Kiselyov develops not one but two algorithms. The first does not have linear complexity, but tends to produce very compact code.
          The second is guaranteed to be of linear complexity, at the cost of being less compact in certain cases.
          Kiselyov's description is somewhat theoretical, so in section~\ref{sec:kiselyov} we describe both algorithms in a way that is straightforward to implement.
    \item We implement a fast combinator graph reduction engine based on the ideas in Miranda~\cite{turner_miranda_1985} and later improvements~\cite{koopman_architecture_1992}.
          We elaborate on its design in sections~\ref{sec:miranda} and~\ref{sec:tigre}.
    \item We evaluate the performance of Miranda, Haskell and our engine on a set of benchmark programs in section~\ref{sec:eval}.
\end{itemize}

For readers unfamiliar with combinatory logic and/or graph reduction, we provide a short introduction to these topics in section~\ref{sec:prelim}.

\section{Preliminaries}
\label{sec:prelim}
\textbf{TODO: write section. Currently contains only a few small fragments}
\subsection{Combinatory Logic}
Starting from a lambda calculus expression, we first translate it into an expression consisting exclusively of the application of a small set of predefined functions, or \textit{combinators}.
It turns out that any lambda calculus expression can be expressed using just three combinators:
\begin{itemize}
    \item $S \ f \ g \ x = f \ x \ (g \ x)$
    \item $K \ x \ y = x$
    \item $I \ x = x$\footnote{It turns out that $SKK = I$, so even this combinator is not strictly necessary, but all reasonable implementations do include $I$, and it simplifies the example.}
\end{itemize}

For example, $\lambda x.x+1$ can be converted into the combinator expression:

\[
    S \ (S \  (K \  +) \  I) \ (K \ 1)
\]

We invite the reader to verify this by applying $x$ to this expression and reducing it to $x+1$ with the usual $\beta$-reduction rule.
While the generated expression is not as easy to read, the simplicity of its components is appealing: to execute a program compiled to combinators, an evaluator only needs to support four operations: the built-in $S$, $K$ and $I$ combinators, and function application\footnote{And any builtins of the language, like the plus operator in the example.}.
Better still, conversion to combinators removes all bound variables.
The runtime need not concern itself with passing arguments, this is all handled by the combinators.
The compiled program is executed using graph reduction, a technique that is also common in other reduction engines\cite{kieburtz_g-machine_1985,fairbairn_tim_1987}.

\subsection{Graph Reduction}
% In the reduction graph, vertices are combinators, constants or function applications, and edges connect the function and argument for application (combinators and constants have no outgoing edges, they are leaf nodes).


\section{Kiselyov's algorithms}
\label{sec:kiselyov}
Kiselyov's paper~\cite{kiselyov_lambda_2018} describes three iterations of his non-linear semantic translation, and finally the linear algorithm.
They are presented as a type system accompanied with operational semantics, with the exception of the $\eta$-optimization given as an OCaml code patch.
OCaml's type system can represent these algorithms very concisely in tagless-final style, but how should we represent them in a more conventional style, possibly in a language that does not have such a strong type system?

\subsection{Strict algorithm}
This is based on the rules in figure 6 of Kiselyov's paper.
We call it \textit{strict} it does not have lazy weakening: most notably it lacks the K-optimization required for full laziness.

The most naive implementation is to perform the type checking, then use the built context to apply the elimination rules and the translated program.
As Kiselyov already notes in his treatment of the linear algorithm further on in the paper, the translation does not actually care what elements are in the context, just that we keep track of the size of the context.
This lets us express compilation as a recursive function:

\begin{equation*}
    \begin{array}{l l l l}
        \strict & z         & = & 1 \models I                                              \\
        \strict & s \ e     & = & n+1 \models (0 \models K) \coprod (n \models c)          \\
                &           &   & \text{where } (n \models c) := \strict e                 \\
        \\
        \strict & \lambda e & = & 0 \models K \; c                                         \\
                &           &   & \text{where } (0 \models c) := \strict e                 \\
        \strict & \lambda e & = & (n-1) \models K \; c                                     \\
                &           &   & \text{where } (n \models c) := \strict e                 \\
        \\
        \strict & e_1 \ e_2 & = & (n \models ((n_1 \models c_1) \coprod (n_2 \models c_2)) \\
                &           &   & \text{where } (n_1 \models c_1) := \strict e_1           \\
                &           &   & \text{where } (n_2 \models c_2) := \strict e_2           \\
                &           &   & \text{where } n := \max n_1 \, n_2                       \\
    \end{array}
\end{equation*}

There are two cases for $\lambda e$, and this is precisely where the number of elements in the context matters:
if the context is empty, the first rule applies, otherwise, we use the second one.
The semantic function may be defined as:

\begin{equation*}
    \arraycolsep=1.4pt
    \begin{array}{l l l l l}
        (0 \models c_1)   & \coprod & (0 \models c_2)   & = & c_1 \ c_2                                         \\
        \\
        (0 \models c_1)   & \coprod & (n_2 \models c_2) & = & (0 \models B c_1) \coprod (n_2 - 1 \models c_2)   \\
        \\
        (n_1 \models c_1) & \coprod & (0 \models c_2)   & = & (0 \models C C c_2) \coprod (n_1 - 1 \models c_1) \\
        \\
        (n_1 \models c_1) & \coprod & (n_2 \models c_2) & = & (n_1 - 1 \models (s \coprod l)) \coprod r)        \\
                          &         &                   &   & \text{where } s := (0 \models S )                 \\
                          &         &                   &   & \text{where } l := (n_1-1 \models c_1 )           \\
                          &         &                   &   & \text{where } r := (n_2-1 \models c_2 )           \\
    \end{array}
\end{equation*}

These simplified functions can be implemented directly and efficiently in a conventional programming language.

\subsection{Lazy weakening}
Adding lazy weakening requires that we track which items in the context are ignored.
We change our context representation from an integer to a list of boolean values.
In the new compilation functions below, we use a shorthand $t$ for the value \textit{true} and $f$ for \textit{false}.
We always match the last element of lists and represent the remainder of the list with $\Gamma$.

\begin{equation*}
    \begin{array}{l l l l}
        \lazy & z         & = & t \models I                                                             \\
        \lazy & s \ e     & = & \Gamma,f \models c                                                      \\
              &           &   & \text{where } (\Gamma \models c) := \lazy e                             \\
        \\
        \lazy & \lambda e & = & \emptyset \models K \; c                                                \\
              &           &   & \text{where } (\emptyset \models c) := \lazy e                          \\
        \lazy & \lambda e & = & (\emptyset \models K) \coprod (\Gamma \models c)                        \\
              &           &   & \text{where } (\Gamma,f \models c) := \lazy e                           \\
        \lazy & \lambda e & = & \Gamma \models K \; c                                                   \\
              &           &   & \text{where } (\Gamma,t \models c) := \lazy e                           \\
        \\
        \lazy & e_1 \ e_2 & = & (\Gamma \models ((\Gamma_1 \models c_1) \coprod (\Gamma_2 \models c_2)) \\
              &           &   & \text{where } (\Gamma_1 \models c_1) := \lazy e_1                       \\
              &           &   & \text{where } (\Gamma_2 \models c_2) := \lazy e_2                       \\
              &           &   & \text{where } \Gamma := \Gamma_1 \sqcup \Gamma_2                        \\
    \end{array}
\end{equation*}

We have introduced yet another case for $\lambda e$, this time to distinguish between $t$ or $f$ as the last element in the context of the inner expression.
There is also the new function $\sqcup$, which we need to implement:

\begin{equation*}
    \begin{array}{l l l l l}
        \Gamma_1    & \sqcup & \emptyset   & = & \Gamma_1                     \\
        \emptyset   & \sqcup & \Gamma_2    & = & \Gamma_2                     \\
        \Gamma_1,t  & \sqcup & \Gamma_2,\_ & = & (\Gamma_1 \sqcup \Gamma_2),t \\
        \Gamma_1,\_ & \sqcup & \Gamma_2,t  & = & (\Gamma_1 \sqcup \Gamma_2),t \\
        \Gamma_1,f  & \sqcup & \Gamma_2,f  & = & (\Gamma_1 \sqcup \Gamma_2),f \\
    \end{array}
\end{equation*}

In our implementation, we unroll the recursion into a while loop, and repeatedly pop elements from the two arrays until both are empty.
This builds the new context backwards, so as a final step the array is reversed.

Alternatively, an implementation can pad the shorter list (at the start!) with $f$ and zip them.
This is particularly convenient for languages that provide a zip function with a default value\footnote{such as \href{https://docs.python.org/3/library/itertools.html\#itertools.zip\_longest}{\texttt{ziplongest}} in Python.}.

Our semantic function now has to handle more cases, and thus is somewhat larger:

\begin{equation*}
    \arraycolsep=1.4pt
    \begin{array}{l l l l l}
        (\emptyset \models c_1)  & \coprod & (\emptyset \models c_2)  & = & c_1 \ c_2                                                \\
        \\
        (\emptyset \models c_1)  & \coprod & (\Gamma_2,t \models c_2) & = & (\emptyset \models B c_1) \coprod (\Gamma_2 \models c_2) \\
        \\
        (\Gamma_1,t \models c_1) & \coprod & (\emptyset \models c_2)  & = & (\emptyset \models C C c_2) \coprod (\Gamma \models c_1) \\
        \\
        (\Gamma_1,t \models c_1) & \coprod & (\Gamma_2,t \models c_2) & = & (\Gamma_1 \models (s \coprod l)) \coprod r)              \\
                                 &         &                          &   & \text{where } s := (\emptyset \models S )                \\
                                 &         &                          &   & \text{where } l := (\Gamma_1 \models c_1 )               \\
                                 &         &                          &   & \text{where } r := (\Gamma_2 \models c_2 )               \\
        \\
        % The new additions
        (\Gamma_1,f \models c_1) & \coprod & (\Gamma_2,f \models c_2) & = & (\Gamma_1 \models c_1) \coprod (\Gamma_2 \models c_2)    \\
        \\
        (\Gamma_1,f \models c_1) & \coprod & (\Gamma_2,t \models c_2) & = & (\Gamma_1 \models (b \coprod l)) \coprod r)              \\
                                 &         &                          &   & \text{where } b := (\emptyset \models B )                \\
                                 &         &                          &   & \text{where } l := (\Gamma_1 \models c_1 )               \\
                                 &         &                          &   & \text{where } r := (\Gamma_2 \models c_2 )               \\
        \\
        (\Gamma_1,t \models c_1) & \coprod & (\Gamma_2,f \models c_2) & = & (\Gamma_1 \models (c \coprod l)) \coprod r)              \\
                                 &         &                          &   & \text{where } c := (\emptyset \models C )                \\
                                 &         &                          &   & \text{where } l := (\Gamma_1 \models c_1 )               \\
                                 &         &                          &   & \text{where } r := (\Gamma_2 \models c_2 )               \\
        \\
        (\emptyset \models c_1)  & \coprod & (\Gamma_2,f \models c_2) & = & (\emptyset \models c_1) \coprod (\Gamma_2 \models c_2)   \\
        \\
        (\Gamma_1,f \models c_1) & \coprod & (\emptyset \models c_2)  & = & (\Gamma_1 \models c_1) \coprod (\emptyset \models c_2)   \\
    \end{array}
\end{equation*}

The first 4 cases are direct translations from the previous definitions, the others are new additions to handle ignored elements.
The last 2 cases are not included in the original paper, but they are necessary to make the pattern matching exhaustive, and are present in the reference OCaml implementation.

\subsection{Eta optimization}
Kiselyov covers eta optimization as a change to his OCaml code rather than typing rules.
Our recursive functions are derived from the typing rules, so these changes are not as straightforward to incorporate.
%Previously Kiselyov's representation consisted of elements $C$, $N$ and $W$, representing closed expressions, a used context element, and an ignored context element respectively.
The introduction of the $V$ element means that a context may now be associated with either a closed expression or the top variable (we reuse $V$ as a marker for this).
Our implementation uses a tagged union to define a type that can be either an expression or the top variable.
For the compilation function, we only need to change the definition of $\lazyeta \ z$ and add an extra case for $\lazyeta \ \lambda e$:

\begin{equation*}
    \begin{array}{l l l l}
        \lazyeta & z         & = & \emptyset \models V                                                          \\
        \lazyeta & s \ e     & = & \Gamma,f \models c                                                           \\
                 &           &   & \text{where } (\Gamma \models c) := \lazyeta e                               \\
        \\
        \lazyeta & \lambda e & = & \emptyset \models I                                                          \\
                 &           &   & \text{where } (\emptyset \models V) := \lazyeta e                            \\
        \lazyeta & \lambda e & = & \emptyset \models K \; c                                                     \\
                 &           &   & \text{where } (\emptyset \models c) := \lazyeta e                            \\
        \lazyeta & \lambda e & = & (\emptyset \models K) \coprod_\eta (\Gamma \models c)                        \\
                 &           &   & \text{where } (\Gamma,f \models c) := \lazyeta e                             \\
        \lazyeta & \lambda e & = & \Gamma \models K \; c                                                        \\
                 &           &   & \text{where } (\Gamma,t \models c) := \lazyeta e                             \\
        \\
        \lazyeta & e_1 \ e_2 & = & (\Gamma \models ((\Gamma_1 \models c_1) \coprod_\eta (\Gamma_2 \models c_2)) \\
                 &           &   & \text{where } (\Gamma_1 \models c_1) := \lazyeta e_1                         \\
                 &           &   & \text{where } (\Gamma_2 \models c_2) := \lazyeta e_2                         \\
                 &           &   & \text{where } \Gamma := \Gamma_1 \sqcup_\eta \Gamma_2                        \\
    \end{array}
\end{equation*}

Our context merge function $\sqcup$ now also depends on the compiled expression, since we have a special case for $V$:

\begin{equation*}
    \begin{array}{l l l l l}
        (\Gamma_1,\_ \models c_1) & \sqcup_\eta & (\emptyset \models V)     & = & \Gamma_1,t                        \\
        (\emptyset \models V)     & \sqcup_\eta & (\Gamma_2,\_ \models c_2) & = & \Gamma_2,t                        \\
        (\emptyset \models c_1)   & \sqcup_\eta & (\emptyset \models V)     & = & t                                 \\
        (\emptyset \models V)     & \sqcup_\eta & (\emptyset \models c_2)   & = & t                                 \\
        (\emptyset \models V)     & \sqcup_\eta & (\emptyset \models V)     & = & \mathbf{impossible}               \\
        \\
        % Original ones
        (\Gamma_1 \models c_1)    & \sqcup_\eta & (\emptyset \models c_2)   & = & \Gamma_1                          \\
        (\emptyset \models c_1)   & \sqcup_\eta & (\Gamma_2 \models c_2)    & = & \Gamma_2                          \\
        (\Gamma_1,t \models c_1)  & \sqcup_\eta & (\Gamma_2,\_ \models c_2) & = & (\Gamma_1 \sqcup_\eta \Gamma_2),t \\
        (\Gamma_1,\_ \models c_1) & \sqcup_\eta & (\Gamma_2,t \models c_2)  & = & (\Gamma_1 \sqcup_\eta \Gamma_2),t \\
        (\Gamma_1,f \models c_1)  & \sqcup_\eta & (\Gamma_2,f \models c_2)  & = & (\Gamma_1 \sqcup_\eta \Gamma_2),f \\
    \end{array}
\end{equation*}

The $V$ value effectively encodes an additional implicit used element in the context.
We also have some new cases for the semantic function:

\begin{equation*}
    \arraycolsep=1.4pt
    \begin{array}{l l l l l}
        % Added for eta optimization
        (\Gamma_1,f \models c_1) & \coprod_\eta & (\emptyset \models V)    & = & c_1                                                        \\
        (\emptyset \models V)    & \coprod_\eta & (\Gamma_2,f \models c_2) & = & (\emptyset \models CI) \coprod_\eta (\Gamma_2 \models c_2) \\

        (\Gamma_1,t \models c_1) & \coprod_\eta & (\emptyset \models V)    & = & (\Gamma_1 \models (s \coprod_\eta l)) \coprod_\eta i       \\
                                 &              &                          &   & \text{where } l := (\Gamma_1 \models c_1 )                 \\
                                 &              &                          &   & \text{where } s := (\emptyset \models S )                  \\
                                 &              &                          &   & \text{where } i := (\emptyset \models I )                  \\
        (\emptyset \models V)    & \coprod_\eta & (\Gamma_2,t \models c_2) & = & (\emptyset \models SI) \coprod_\eta (\Gamma_2 \models c_2) \\
        (\emptyset \models c_1)  & \coprod_\eta & (\emptyset \models V)    & = & c_1                                                        \\
        (\emptyset \models V)    & \coprod_\eta & (\emptyset \models c_2)  & = & CI c_2                                                     \\
        (\emptyset \models V)    & \coprod_\eta & (\emptyset \models V)    & = & \mathbf{impossible}                                        \\
        \\

        (\Gamma_1 \models c_1)   & \coprod_\eta & (\Gamma_2 \models)       & = & (\Gamma_1 \models c_1) \coprod (\Gamma_2 \models)          \\
    \end{array}
\end{equation*}

The case $(\emptyset \models V) \coprod (\emptyset \models V) $ is impossible in this translation, implementations may throw an error or leave it as undefined behavior.
\textbf{TODO:} Why is this an impossible case?

With the addition of the expression value to $\sqcup_\eta$, the function now takes the same input as $\coprod_\eta$ and has very similar matching patterns.
Our implementation, therefore, folds context merging into $\coprod_\eta$ to make the code more concise.

\subsection{Linear algorithm}
The implementation of the linear algorithm is much simpler because it is based on the $\strict$ algorithm.
The compilation function is identical save for a different semantic function $\coprod_{\text{linear}}$:

\begin{equation*}
    \begin{array}{l l l l}
        \linear & z         & = & 1 \models I                                                              \\
        \linear & s \ e     & = & n+1 \models (0 \models K) \coprod (n \models c)                          \\
                &           &   & \text{where } (n \models c) := \linear e                                 \\
        \\
        \linear & \lambda e & = & 0 \models K \; c                                                         \\
                &           &   & \text{where } (0 \models c) := \linear e                                 \\
        \linear & \lambda e & = & (n-1) \models K \; c                                                     \\
                &           &   & \text{where } (n \models c) := \linear e                                 \\
        \\
        \linear & e_1 \ e_2 & = & (n \models ((n_1 \models c_1) \coprod_{\text{linear}} (n_2 \models c_2)) \\
                &           &   & \text{where } (n_1 \models c_1) := \linear e_1                           \\
                &           &   & \text{where } (n_2 \models c_2) := \linear e_2                           \\
                &           &   & \text{where } n := \max n_1 \, n_2                                       \\
    \end{array}
\end{equation*}

below we give the corresponding semantic function, which is no longer recursive, making this algorithm linear:

\begin{equation*}
    \arraycolsep=1.4pt
    \begin{array}{l l l l l}
        (0 \models c_1)   & \coprod & (0 \models c_2)   & = & c_1 \ c_2                               \\
        \\
        (0 \models c_1)   & \coprod & (n \models c_2)   & = & B_n \ c_1 \ c_2                         \\
        \\
        (n \models c_1)   & \coprod & (0 \models c_2)   & = & C_n \ c_1 \ c_2                         \\
        \\
        (n \models c_1)   & \coprod & (n \models c_2)   & = & S_n \ c_1 \ c_2                         \\
        \\
        (n_1 \models c_1) & \coprod & (n_2 \models c_2) & = & B_{n_2-n_1} \ (S_{n_1} \ c_1) \ c_2     \\
                          &         &                   &   & \text{where } n_1 < n_2                 \\
        (n_1 \models c_1) & \coprod & (n_2 \models c_2) & = & C_{n_1-n_2} \ (B_{n_1-n_2} \ c_1) \ c_2 \\
                          &         &                   &   & \text{where } n_1 > n_2                 \\
    \end{array}
\end{equation*}

\textbf{TODO: } Can we add lazy weakening and/or eta optimization?

\section{Miranda}
\label{sec:miranda}
For our base implementation, we try to stick to Miranda's design as much as possible.
While there is published work on Miranda~\cite{turner_miranda_1985}, it does not provide much detail on the reduction engine.
Fortunately, the source code for Miranda is now freely available~\cite{noauthor_open_2021}, and from the code, we can deduce that its design is very similar to SASL~\cite{turner_new_1979}, an earlier language developed by Turner.

Miranda uses a graph reduction engine, so after a program has been converted into combinatory logic using Turner's abstraction algorithm~\cite{turner_another_1979}, it is loaded into a graph structure.
The graph is binary: every node has exactly two children, and the node itself represents the application of the right node to the left one.
Let us start with an example program $SKK \ 3$.
The $S$ combinator takes 3 arguments, but currying lets us write it as $((SK) \; K)\ 3$.
In this form, it is straightforward to construct the associated binary graph, shown in figure~\ref{fig:skk3}.

\begin{figure}
    \includegraphics[width=.23\columnwidth]{skk3}
    \centering
    \caption{$SKK \ 3$ in graph representation.}
    \label{fig:skk3}
\end{figure}

To reduce this graph, we follow the left pointers until we find a combinator to apply.
As we traverse the graph along what is often called the \textit{spine}, we keep the nodes we have seen on a stack, because their right nodes contain the arguments to the combinator we eventually find.

In this example graph, after following two pointers we find the $S$ combinator, and we apply the definition $S f g x \Rightarrow (f x) (g x)$ to rewrite the graph, as shown in figure~\ref{fig:skk3_sred}.

\begin{figure}
    \includegraphics[width=.8\columnwidth]{skk3_sred}
    \centering
    \caption{
        First reduction step for $SKK \ 3$.
        One of the K combinators is underlined to make them easier to distinguish.
    }
    \label{fig:skk3_sred}
\end{figure}

The reduction process continues until the program has been reduced to a constant value, or there are insufficient arguments for the next combinator to reduce.
The expression is said to be in \textit{weak head normal form}: some inner part of the expression may be reducible, but we only perform outermost reduction, so this is as close as we can get to normal form.

\subsection{Sharing}
In the reduction in figure~\ref{fig:skk3_sred}, we have copied the value $3$ to two nodes.
For another reduction where the $x$ value is a pointer to a subgraph, performing the reduction may result in multiple pointers to the same expression.
Expressions in Miranda are \textit{referentially transparent}: we can safely replace any expression with the value it computes.
Computing $x$ in both branches would therefore be wasteful.
Instead, we would like to compute it once (in whatever branch runs first) and have the second branch directly reuse the result.
It turns out that this is not too difficult to implement: when we make a reduction step, we update the outermost node with the contents of the new outermost node.
In figure~\ref{fig:skk3_sred}, this would mean we overwrite node 1 with the contents of node 4.
Now any other pointers to node 1 automatically point to the reduced equivalent.
If the expression reduces to a single value $v$ (say an integer), we can use the $I$ combinator to make an \textit{indirection node} $I v$.

\subsection{Representing the graph}
Miranda represents the graph using three arrays, \texttt{hd} (for head) stores the left pointer, \texttt{tl} (for tail) stores the right pointer, and \texttt{tag} stores metadata for the cell.
Owing to its early inception when 64-bit machines were rare, \texttt{hd} and \texttt{tl} are 32 bits wide.
\texttt{tag} only needs to store a few bit flags and thus is a single byte wide.
Our implementation stores two flags in \texttt{tag}:
\begin{itemize}
    \item \texttt{WANTED}: Set if this cell is currently in use. Cells without this bit set are considered free and may be overwritten to store new nodes in the graph. More on this in the section on Garbage collection.
    \item \texttt{RHS\_INT}: Set if the right pointer is not a pointer but an integer value. Note that the left pointer can never be an integer because the left pointer is always a function for which the right pointer is the first argument.
\end{itemize}

Miranda integers have unlimited precision, using GNU MP~\cite{gnump} internally.
For simplicity (and performance), our implementation instead treats the cell pointer as a 32-bit signed integer.

It is unclear why a representation with three separate arrays was chosen over a single array where each element contains a 'cell' struct with a head, tail and tag.
We suspect decomposing the graph into separate arrays leads to poor data locality, as almost any operation will access all three parts of a cell.
Our base implementation respects this design choice, later implementations do not.

Miranda reserves the lower range of cell pointer values for special purposes:
\begin{itemize}
    \item 0..255 represents the Latin 1 character set.
    \item 256..305 for internal use in the lexer.
    \item 306..446 to encode combinators.
\end{itemize}

The first 446 cells in the heap are unused: when the reduction engine encounters their value, they are interpreted as a character, lexer rule or combinator.
This explains why we have to tag integers but not combinators or character values.

Our implementation does not support character values and needs no reserved number for the lexer, so we can encode the first combinator as $0$.
The bulk combinators introduced by the $\linear$ algorithm do complicate the encoding somewhat:
in principle, there is now an infinite amount of possible combinators.
However, compiled programs only contain a finite subset of those combinators, and the reduction process only creates combinators that were present in the original program.
We can have an efficient encoding of combinators, but only if we generate it for specific programs.
Our implementation keeps an array of function pointers, each pointing to the code to reduce a particular combinator.
The array is populated as the compiled program is loaded into the graph representation:
when we encounter a combinator we have not seen before, its implementation is added to the array, and the combinator is encoded into the graph as its index into the array.
At runtime, combinator resolution is done by indexing into the array and calling the associated function.

\subsection{Strict combinators}
Miranda has special built-in combinators to perform arithmetic operations and compare numbers.
Where most combinators place no restrictions on their arguments, these combinators require their arguments to be fully reduced to integers (hence call them \textit{strict}), and so require special treatment.
We found Miranda's implementation difficult to follow, the approach we describe here is the one taken for our implementation, and may not fully correspond to Miranda's.

When a \textit{strict} combinator is about to be reduced, the engine inspects the arguments.
If all arguments are reduced, the combinator reduction is performed as usual.
If one or more arguments are not yet reduced, we push the pointers to those arguments onto the stack and proceed to reduce from the top of the stack.
Eventually, the top argument will have been fully reduced, producing an integer value.
In general, if a reduction results in an integer value, it can mean one of two things:
\begin{itemize}
    \item The value is the result of the program.
    \item The value is one of the arguments for a strict combinator.
\end{itemize}
We distinguish between these cases by looking at the size of the stack: if it is empty, we have computed the final result of the program.
Otherwise, we continue reducing from the top of the stack, which will be either another argument or the original combinator expression.
The pointer to the original complex argument is replaced with an indirection node to the value, using the update logic described earlier.

As an example, consider the expression $+ \ 1 \ (K \ 2 \ 3)$.
After we have traversed the spine and encountered the $+$ combinator, the engine notices that the second argument is not yet reduced, and adds it to the stack.
Figure~\ref{fig:add_step1} shows the state of the graph at this point in the reduction process.

\begin{figure}
    \includegraphics[width=.8\columnwidth]{add_step1}
    \centering
    \caption{
        Graph of $+ \ 1 \ (K \ 2 \ 3)$ after the second argument has been added to the stack.
    }
    \label{fig:add_step1}
\end{figure}

Once $K \ 2 \ 3$ has been reduced to $3$, the engine observes that the stack is not yet empty, so it creates an indirection node and resumes reduction from the top of the stack.
Figure~\ref{fig:add_step2} reflects this state.

\begin{figure}
    \includegraphics[width=.8\columnwidth]{add_step2}
    \centering
    \caption{
        Graph of $+ \ 1 \ (K \ 2 \ 3)$ after the second argument has been reduced.
    }
    \label{fig:add_step2}
\end{figure}

This example shows that it is not sufficient to check the \texttt{tag} of each argument to see if it is an integer: indirection nodes also count as fully reduced.

\subsection{Garbage collection}
The graph reduction process may lead to some nodes becoming unreachable.
Coming back to the example in figure~\ref{fig:skk3_sred}, after the reduction step nodes 2 and 3 are no longer used: they are \textit{garbage}.
In this example, it is easy to conclude which nodes are garbage, but in larger programs, there are often multiple references to the same node, so we cannot mark nodes as garbage during the reduction step.
Miranda employs a simple mark-and-sweep garbage collector that kicks in when the engine runs out of free cells while allocating a new node.
In the first phase, it zeroes out the \texttt{WANTED} bit on all tags in the heap.
Then in the marking phase, starting from the elements currently on the stack\footnote{
    Miranda keeps its reduction stack on the C stack.
    This makes it difficult to reliably enumerate all cell pointers on the stack at a given point in time, because the compiler may choose to keep some of the pointers in registers.
    For this reason, users are instructed not to enable optimizations when compiling Miranda, which hurts performance but is necessary for correctness.
    When Miranda was developed, compilers were not advanced enough to perform such optimizations, so this was not an issue.
}, the garbage collector traverses the graph and sets the \texttt{WANTED} bit on all reachable nodes.
There is no real sweep phase: instead, the allocation routine walks over the tag array until it finds a cell that is not marked as \texttt{WANTED}.
This also means that there is no list of currently free cells, which we suspect may lead to performance issues in large heaps.

We consider the garbage collector in Miranda to be somewhat simplistic and inefficient, and we suspect there is much to improve in terms of efficiency.
Our benchmark programs do not use too much heap space, so we choose not to focus our efforts on this, and defer optimizations on this front to future work.

\section{TIGRE}
\label{sec:tigre}
\subsection*{Eliminating tags}
Tags are commonly used to distinguish pointers, combinators and literal values.
We get rid of the literal value tag by making all literals go through an indirection node, and introducing a special \texttt{LIT} combinator for such indirection nodes.
To determine if a right-hand side is a literal, we can check for the \texttt{LIT} combinator rather than a tag.
In the TIGRE paper, there is also a pointer and combinator tag, but with Miranda's design, this is not necessary.
If we insist, that final tag value can be put as the lowest bit in the pointer value, since a pointer is typically aligned to some boundary.
We are working with 32-bit (4-byte) wide values, for which on X86 we can assume 4-byte alignment, giving us 2 bits to play with.

\subsection*{Threaded code interpreter}
We make the nodes themselves executable code.
For nodes that represent the combinators, a pointer to that node is just a pointer to the subroutine that implements the combinator.
For application nodes, they are a jump instruction together with the left node as the target (so the left node is the width of one instruction).
The jump instruction should push the current PC onto the stack, which means the stack now directly represents the spine.

The TIGRE style requires that we make our memory writable and executable, which is problematic in many systems.
It seems to work okay on Linux though, so we can use it.

The instruction to use on X86 is \texttt{call}.
It takes one parameter, which is a PC-relative offset.
When we create a node, we should subtract the target position from the location where we are writing the instruction, and use that as the jump parameter.

The trampolines can be generated or hand-coded ahead of time, so our runtime only needs to assemble \texttt{CALL} instructions.

For combinators, we can generate a trampoline that grabs the arguments from the stack, puts them in registers and calls the rust implementation.

The \texttt{call} instruction pushes the \texttt{EIP} register onto the stack, which contains the address of the 'instruction' after the \texttt{call}.
In our calling convention, this means the stack consists of pointers to the right-hand sides, very convenient.

A \texttt{push} instruction first decrements the stack pointer \texttt{rsp}, then writes the new value to the address of  \texttt{rsp}.
Assembly to load the value of the top of the stack is therefore: \texttt{mov rax, [rsp]}.
To load the second value: \texttt{mov rax, [rsp+8]}.

It seems to be a good idea to align nodes at a 16-byte boundary for better jump performance:
https://groups.google.com/g/golang-nuts/c/dhGbgC1pAmA
do not put more than 2 branches in a 16-byte block.

Encoding of the call instruction is \texttt{E8} \textit{rel32}, where \textit{rel32} is a 32-bit (little-endian) offset from the \emph{next} instruction.
\textbf{TODO}

Describe changes made to align with TIGRE.

Compare performance with Miranda-style engine.

TODO:
\begin{itemize}
    \item Garbage collection
    \item Bulk combinators
    \item Integration tests
\end{itemize}

\section{Performance evaluation}
\label{sec:eval}
Programs:
\begin{itemize}
    \item ackermann
    \item digits of e
    \item linfib
    \item lsort
    \item nfib
    \item primes
    \item queens
    \item tak
    \item towers of hanoi
    \item treesort
\end{itemize}

Evaluate performance of:

\begin{itemize}
    \item Bracket abstraction
    \item Kiselyov
    \item GHC
\end{itemize}

Suggestion from \textit{Common Benchmarking Pitfalls}: Always look at your distribution.
When you have run benchmarks, take a look at the times for each sample.

\section{Conclusion}
% Repeat the main question / objective of your research

% Give the answer to the question
Source code for our Superg evaluator is available at \url{https://github.com/wildarch/mono/tree/main/experiments/superg}.

% Why is this the answer? Present the main arguments

% What are the implications of this answer?

% Suggestions for future research

% FINAL CHECK: Can the conclusion be read independently?

\bibliographystyle{IEEEtran}
\bibliography{zotero, references}

\end{document}
